{
  "hash": "a67af1085030cb5977c4f37cb85809ed",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Spatial Predictive Analysis\"\nsubtitle: \"Building a spatial predictive model using a 311 service request type\"\nauthor: \"Christine\"\ndate: today\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n## About This Exercise\n\nIn this exercise, I will build a spatial predictive model for burglaries using count regression and spatial features.\n\n# Setup\n\n\n\n# Part 1: **Data Loading & Exploration**\n\n（改）This chunk loads and prepares all spatial inputs for the analysis: it reads the vacant and abandoned houses CSV, parses the service request date, filters records with valid coordinates from 2017, converts them to an sf point layer in WGS84 and reprojects to ESRI:102271; it reads the burglaries shapefile and reprojects to the same CRS; it downloads police districts and police beats from the Chicago open data portal, reprojects them, and keeps their key ID fields; it loads the Chicago city boundary from GitHub and reprojects it.\n\n## 1.1: Load Chicago Spatial Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 25 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 277 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\") %>%\n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `chicagoBoundary' from data source \n  `https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -87.8367 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Loaded spatial boundaries\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded spatial boundaries\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police districts: 25 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police beats: 277 \n```\n\n\n:::\n:::\n\n\n## 1.2: Load Burglary Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(\"D:/MUSA5080PPA/portfolio-setup-ChristineCui12/labs/lab_4/data/burglaries.shp\") %>% \n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `burglaries' from data source \n  `D:\\MUSA5080PPA\\portfolio-setup-ChristineCui12\\labs\\lab_4\\data\\burglaries.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 7482 features and 22 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 340492 ymin: 552959.6 xmax: 367153.5 ymax: 594815.1\nProjected CRS: NAD83(HARN) / Illinois East\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Loaded burglary data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of burglaries: 7482 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - CRS:\", st_crs(burglaries)$input, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - CRS: ESRI:102271 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Date range:\", min(burglaries$Date, na.rm = TRUE), \"to\", \n    max(burglaries$Date, na.rm = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Date range: 17167 to 17532 \n```\n\n\n:::\n:::\n\n\n**Question 1.2:** What spatial patterns do you observe? Are burglaries evenly distributed across Chicago? Where are the highest concentrations? What might explain these patterns?\n\n*Your answer here:*\n\n\\- Spatial patterns:\n\n\\- Evenly distributed: No, it's dispersed obviously and it's concentrated in 2 parts-north and south. - Highest concentrations: The highest concentration is in the south side.\n\n\\- Explaination:\n\n## 1.3: Load 311 Street Lights Out Calls\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlights_out <- read_csv(\"D:/MUSA5080PPA/portfolio-setup-ChristineCui12/labs/lab_4/data/Alley_Lights_Out_2025.csv\")%>%\n  mutate(date_received = mdy(`Creation Date`)) %>%\n  filter(!is.na(Latitude), !is.na(Longitude), year(date_received) == 2017) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded lights out calls\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded lights out calls\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of calls:\", nrow(lights_out), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of calls: 27890 \n```\n\n\n:::\n:::\n\n\nThe violation type I analyze is xxxx. Unlike abandoned cars, which can be towed and moved, vacant houses are fixed and often persist for years. That persistence implies two things: (1) counts and hotspots of vacancy are likely stable over a one-year window, and (2) vacancy may be strongly associated with burglary risk, because prolonged emptiness weakens guardianship and natural surveillance around the property.\n\nFor modeling, this slow-moving signal should yield high spatial and temporal autocorrelation, making vacancy a strong predictor of year-to-year burglary variation at the grid-cell level. Still, correlation isn’t causation: shared structural conditions (poverty, tenure, disinvestment) can drive both vacancy and burglary. We address this with controls (income, renter share, poverty, age composition), but some confounding may remain. Finally, 311 reports likely undercount vacancy in high-need areas, so we treat them as a conservative proxy. Given the stability of vacancy, we expect spatial cross-validation to look stronger than pure out-of-time (2018) validation—precisely what our LOGO vs. temporal checks assess.\n\n## 1.4: Visualize the spatial distribution\n\nThis chunk creates two complementary maps to explore vacant and abandoned house locations in 2017: a point map that plots every record on top of the Chicago boundary, and a filled kernel density surface that highlights areas with higher concentrations of points; both layers use the same CRS and styling for consistency, then the two plots are combined side by side with a shared annotation. Note that the combined plot title currently says “Spatial Distribution of Burglaries in Chicago,” which does not match the data being mapped; change it to “Spatial Distribution of Vacant and Abandoned Houses in Chicago” if you want the caption to reflect the content.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = lights_out, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Lights out Locations\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(lights_out))\n  )\n\n# Density surface using modern syntax\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = data.frame(st_coordinates(lights_out)),\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"  # Modern ggplot2 syntax (not guide = FALSE)\n  ) +\n  labs(\n    title = \"Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Combine plots using patchwork (modern approach)\np1 + p2 + \n  plot_annotation(\n    title = \"Spatial Distribution of Lights out in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-points-1.png){width=1440}\n:::\n:::\n\n\n（改）From the maps above, we note that most reports are concentrated on the South Side, forming a broad high-intensity corridor from the south-central area toward the southeast; a smaller secondary cluster appears on the southwest side. The North and far Northwest sides show relatively few points, and the near-north lakefront is especially sparse. Overall, the pattern is distinctly uneven across the city, with clear hot spots in the south and southeast and cooler areas in the north and northwest, consistent with strong spatial clustering rather than a uniform distribution.\n\n# Part 2: **Fishnet Grid Creation and Distribution**\n\n(改)This section constructs a regular analysis grid for Chicago, aggregates both vacant or abandoned house reports and burglary incidents to that grid, and then maps the resulting counts so we can inspect how vacancy is distributed across space before modeling.\n\nReasons for using a regular grid: Existing boundaries like neighborhoods or census tracts尺度不一样，rbitrary, unequal sizes, Modifiable Areal Unit Problem. - Pros and Cons: Fishnet grid has Consistent size, no boundary bias. We use fishnet because: Standard approach in predictive policing, Easier spatial operations, Consistent unit of analysis. But it has Arbitrary, may split “natural” areas.\n\n## 2.1: Fishnet Creation\n\n（改）\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Created fishnet grid\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of cells: 2458 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell size: 500 x 500 meters\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell area: 250000 square meters\n```\n\n\n:::\n:::\n\n\n## 2.2: Aggregate Burglaries to Grid\n\n（改写）\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBurglary count distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$countBurglaries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   3.042   5.000  40.000 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCells with zero burglaries: 781 / 2458 ( 31.8 %)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize aggregated counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Burglaries\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root for better visualization of skewed data\n    breaks = c(0, 1, 5, 10, 20, 40)\n  ) +\n  labs(\n    title = \"Burglary Counts by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago 2017\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-fishnet-burglaries-1.png){width=768}\n:::\n:::\n\n\n**Question:** What is the distribution of burglary counts across cells? Why do so many cells have zero burglaries? Is this distribution suitable for count regression? (Hint: look up overdispersion)\n\n*Your answer here:* - Distribution of burglary counts: - Reasons for cells have zero burglaries: - Suitability for count regression: No, 有太多0值，代表数据非常分散，方差应该大于平均值。泊松分布cannot handle overdispersion and will underestimated if overdispersed. Poisson assumption: Variance = Mean, but Reality with crime data: Variance \\> Mean ,所以不符合泊松分布的假设，所以要用负二向式回归。\n\n## 2.3: Count of Streets Lights out per Cell\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aggregate lights out calls to fishnet\nlightsout_fishnet <- st_join(lights_out, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(lights_out = n())\n\n# Join to fishnet\nfishnet <- fishnet %>%\n  left_join(lightsout_fishnet, by = \"uniqueID\") %>%\n  mutate(lights_out = replace_na(lights_out, 0))\n\ncat(\"Abandoned car distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAbandoned car distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$lights_out)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    1.00    7.00   11.35   17.00  217.00 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize aggregated counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = lights_out), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Lights Out\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root for better visualization of skewed data\n    breaks = c(0, 1, 5, 10, 20, 40)\n  ) +\n  labs(\n    title = \"Alley Lights Out by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago 2017\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-fishnet-lightsout-1.png){width=768}\n:::\n:::\n\n\n**Question 4.1:** Do you see a visual relationship between abandoned cars and burglaries? What does this suggest?\n\n# Part 3: Create **Spatial Features**\n\n(改)This section engineers spatial predictors from the vacancy surface and adds contextual controls. It measures proximity to vacant structures, detects statistically significant clusters, converts those clusters into a distance-to-hotspot feature, and enriches the grid with police districts and ACS demographics for use in modeling burglary counts.\n\n## 3.1: **K-**Nearest Neighbor Features\n\nCount in a cell is one measure. Distance to the nearest 3 abandoned cars captures local context.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate mean distance to 3 nearest abandoned cars\n# (Do this OUTSIDE of mutate to avoid sf conflicts)\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nlightsout_coords <- st_coordinates(lights_out)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(lightsout_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    lights_out.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated nearest neighbor distances\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$lights_out.nn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   4.602  102.009  172.653  295.489  328.127 2313.532 \n```\n\n\n:::\n:::\n\n\n**Question 4.2:** What does a low value of `abandoned_cars.nn` mean? A high value? Why might this be informative?\n\n*Your answer here:*\n\n## 3.2: Local Moran's I analysis\n\n（改）The code creates a k-nearest neighbor weights matrix on grid centroids (k = 5), runs Local Moran’s I on the abandoned_houses counts, and generates a categorical label (High-High, Low-Low, High-Low, Low-High, or Not Significant). This identifies locations where there are hotspots, coldspots, or outliers. This is useful in substantivbe interpretations to discover whether vacnact or abandoned households are in-step or spatially clustered with neighboring households. It actually supports our initial theory that house abandonment (foreclosure) is likely to occur in generally similar neighborhoods.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n  \n  # Create spatial weights\n  coords <- st_coordinates(st_centroid(data))\n  neighbors <- knn2nb(knearneigh(coords, k = k))\n  weights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n  # Calculate Local Moran's I\n  local_moran <- localmoran(data[[variable]], weights)\n  \n  # Classify clusters\n  mean_val <- mean(data[[variable]], na.rm = TRUE)\n  \n  data %>%\n    mutate(\n      local_i = local_moran[, 1],\n      p_value = local_moran[, 5],\n      is_significant = p_value < 0.05,\n      \n      moran_class = case_when(\n        !is_significant ~ \"Not Significant\",\n        local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n        local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n        local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n        local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n        TRUE ~ \"Not Significant\"\n      )\n    )\n}\n\n# Apply to abandoned cars\nfishnet <- calculate_local_morans(fishnet, \"lights_out\", k = 5)\n```\n:::\n\n\n## 3.3: **Identify Hot Spots and Cold Spots**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Lights out Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-morans-1.png){width=768}\n:::\n:::\n\n\n（改）The LISA map shows vacancy hot spots concentrated on the South and Southeast sides, with additional pockets on the Southwest and a few small clusters on the West Side. Most cells are “Not Significant,” which means their vacancy levels are either average or lack strong similarity with neighbors at the k = 5 neighborhood scale. The few “Low-High” cells appear along the fringes of hot areas and indicate local dips embedded within otherwise high-vacancy neighborhoods, consistent with edge effects at cluster boundaries. Overall, the pattern reinforces our earlier findings: vacancy is highly clustered rather than uniform, with multi-cell cores in the south that are likely to be influential in burglary risk modeling and useful for distance-to-hotspot features.\n\n## 3.4: Distance to Hot Spots\n\n（改）The code extracts centroids of cells labeled High-High, unions them into a single geometry, and computes the distance from each grid centroid to the nearest hotspot. The resulting dist_to_hotspot feature captures how far a location is from the nearest vacancy hot area and defaults to zero when no significant hotspots are found.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to lights out hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated distance to lights out hot spots\n  - Number of hot spot cells: 193 \n```\n\n\n:::\n:::\n\n\n**Question 4.3:** Why might distance to a cluster of abandoned cars be more informative than distance to a single abandoned car? What does Local Moran's I tell us?\n\n*Your answer here:*\n\n## 3.4: Join **Additional Contextual Data**\n\n（改）The code assigns each grid cell to a police district, then downloads 2017 ACS tract data for Cook County, computes demographic and socioeconomic percentages and median income, and joins these attributes to the grid where cells intersect tracts. These controls (race or ethnicity shares, poverty, renter share, vacancy, age structure, and income) provide broader structural context for explaining burglary patterns beyond vacancy alone.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join district information to fishnet\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Joined police districts\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Districts: 22 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cells: 1708 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacs_vars <- c(\n  total_pop = \"B01003_001\",\n  med_income = \"B19013_001\",\n  # Male 65 years and over (sum of 6 categories)\n  male_65_66 = \"B01001_020\",\n  male_67_69 = \"B01001_021\",\n  male_70_74 = \"B01001_022\",\n  male_75_79 = \"B01001_023\",\n  male_80_84 = \"B01001_024\",\n  male_85_up = \"B01001_025\",\n  # Female 65 years and over (sum of 6 categories)\n  female_65_66 = \"B01001_044\",\n  female_67_69 = \"B01001_045\",\n  female_70_74 = \"B01001_046\",\n  female_75_79 = \"B01001_047\",\n  female_80_84 = \"B01001_048\",\n  female_85_up = \"B01001_049\"\n)\n\ntracts_all <- get_acs(\n  geography = \"tract\",\n  state = \"IL\",\n  county = \"Cook\",\n  variables = acs_vars,\n  output = \"wide\",\n  year = 2017, \n  geometry = TRUE \n) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n```\n\n\n:::\n\n```{.r .cell-code}\n  # Calculate the combined 65+ population and rename variables\n\ntracts_chi <- tracts_all %>%\n  st_transform(st_crs(chicagoBoundary)) %>%\n  st_filter(chicagoBoundary, .predicate = st_intersects) %>%\n  dplyr::mutate(\n    pop_65_over = (male_65_66E + male_67_69E + male_70_74E + male_75_79E + male_80_84E + male_85_upE +\n                  female_65_66E + female_67_69E + female_70_74E + female_75_79E + female_80_84E + female_85_upE),\n    pct_65_over = 100 * pop_65_over / pmax(total_popE, 1),\n    total_pop = total_popE,\n    med_income = med_incomeE\n  ) %>%\n  # Select and rename final columns for clarity and consistency\n  dplyr::select(GEOID,total_pop,med_income,pop_65_over,pct_65_over)\n# Join to fishnet\nfishnet <- fishnet %>%\n  st_join(tracts_chi, join = st_intersects, left = TRUE)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load vacant buildings data\nvacant <-\n  st_read(\"data/Vacant_and_Abandoned_Buildings.geojson\", quiet = TRUE) %>%\n  st_transform(\"ESRI:102271\")\n# Spatial join.\nvacant_fishnet <- st_join(vacant, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(count_vacant = n())\n# Join to fishnet\nfishnet <- fishnet %>%\n  left_join(vacant_fishnet, by = \"uniqueID\") %>%\n  mutate(count_vacant = replace_na(count_vacant, 0))\n```\n:::\n\n\n# Part 4: Model Fitting\n\n（改）This section prepares the modeling frame, fits a Poisson and a Negative Binomial count model for burglaries using vacancy features and ACS controls, checks for overdispersion, and selects the preferred specification based on AIC for downstream prediction and validation.\n\n## 4.1: Poisson Regression\n\n（改）The code builds fishnet_model by dropping geometry, selecting the outcome burglaries, adding vacancy predictors (abandoned_houses, nearest vacancy distance, distance to vacancy hotspots), and including demographic and socioeconomic controls. Percentage variables are rescaled to proportions and median income is log transformed to reduce skew. A Poisson GLM with log link is then estimated, and a summary is printed to inspect coefficients and standard errors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    lights_out,\n    lights_out.nn,\n    dist_to_hotspot,\n    med_income,\n    pct_65_over,\n    count_vacant\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Prepared modeling data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Observations: 4204 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Variables: 9 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot + med_income + pct_65_over + count_vacant,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot + med_income + pct_65_over + count_vacant, \n    family = \"poisson\", data = fishnet_model)\n\nCoefficients:\n                     Estimate    Std. Error z value             Pr(>|z|)    \n(Intercept)      2.2935556927  0.0326873382  70.166 < 0.0000000000000002 ***\nlights_out       0.0029259386  0.0004614293   6.341       0.000000000228 ***\nlights_out.nn   -0.0029046996  0.0000914734 -31.755 < 0.0000000000000002 ***\ndist_to_hotspot -0.0000613090  0.0000063612  -9.638 < 0.0000000000000002 ***\nmed_income      -0.0000036522  0.0000003212 -11.370 < 0.0000000000000002 ***\npct_65_over     -0.0200035311  0.0014396462 -13.895 < 0.0000000000000002 ***\ncount_vacant     0.0014450388  0.0002285951   6.321       0.000000000259 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 15489  on 4203  degrees of freedom\nResidual deviance: 12169  on 4197  degrees of freedom\nAIC: 23225\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n**Question:** Interpret the coefficients. Which variables are significant? What do the signs (positive/negative) tell you?\n\n（改）Burglary counts increase with more vacant houses in a cell and with closer proximity to vacancy. Each additional vacant house is associated with about 4.5% higher expected burglaries (IRR ≈ exp(0.0439) = 1.045). Greater distance to the nearest vacant house lowers risk: a 100 m increase corresponds to ≈ 6.7% lower expected burglaries (IRR ≈ exp(−0.0006906×100) = 0.933). Being farther from vacancy hotspots also reduces risk slightly: 1 km farther gives ≈ 2.7% lower rates (IRR ≈ exp(−0.0000279×1000) = 0.973). Neighborhood structure matters: higher renter share is strongly positive (a 10 percentage-point increase → IRR ≈ exp(0.1×1.640) = 1.18, or +18%), higher log income is positive (IRR ≈ exp(0.394) = 1.48 per one-log increase), and percent Black is positive (10 percentage-points → \\~2% higher, IRR ≈ 1.02). Percent Hispanic and ages 45–64 are not significant. Percent in poverty is negative and significant (10 percentage-points → \\~10% lower, IRR ≈ exp(−0.1056) = 0.90), likely reflecting overlap with renter share and income. Percent 65+ is negative and significant (10 percentage-points → \\~13% lower, IRR ≈ exp(−0.1473) = 0.86).\n\n## 4.2: Check for Overdispersion\n\nPoisson regression assumes mean = variance. Real count data often violates this (overdispersion).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDispersion parameter: 3.12 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRule of thumb: >1.5 suggests overdispersion\n```\n\n\n:::\n\n```{.r .cell-code}\nif (dispersion > 1.5) {\n  cat(\"⚠ Overdispersion detected! Consider Negative Binomial model.\\n\")\n} else {\n  cat(\"✓ Dispersion looks okay for Poisson model.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n⚠ Overdispersion detected! Consider Negative Binomial model.\n```\n\n\n:::\n:::\n\n\n## 4.3: Negative Binomial Regression\n\n(改)Overdispersion was substantial (dispersion ≈ 2.79), so moving to a Negative Binomial was appropriate\n\nIf overdispersed, we use **Negative Binomial regression** (more flexible).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot + med_income + pct_65_over + count_vacant,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot + med_income + pct_65_over + count_vacant, \n    data = fishnet_model, init.theta = 1.972735443, link = log)\n\nCoefficients:\n                    Estimate   Std. Error z value             Pr(>|z|)    \n(Intercept)      2.279286029  0.058481245  38.975 < 0.0000000000000002 ***\nlights_out       0.003502754  0.000965502   3.628             0.000286 ***\nlights_out.nn   -0.003074634  0.000137026 -22.438 < 0.0000000000000002 ***\ndist_to_hotspot -0.000056394  0.000010841  -5.202          0.000000197 ***\nmed_income      -0.000002855  0.000000542  -5.268          0.000000138 ***\npct_65_over     -0.022029975  0.002449034  -8.995 < 0.0000000000000002 ***\ncount_vacant     0.002048773  0.000481459   4.255          0.000020873 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.9727) family taken to be 1)\n\n    Null deviance: 6016.3  on 4203  degrees of freedom\nResidual deviance: 4699.3  on 4197  degrees of freedom\nAIC: 19782\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.9727 \n          Std. Err.:  0.0714 \n\n 2 x log-likelihood:  -19766.1740 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson AIC: 23224.7 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNegative Binomial AIC: 19782.2 \n```\n\n\n:::\n:::\n\n\n（改）it fits much better (AIC 19,659; residual deviance 4,837 on 4,193 df) and estimates an overdispersion parameter θ ≈ 2.21. Vacancy intensity and proximity both raise burglary risk; tenure structure (more renters) is a strong correlate; older population share is associated with lower risk. The Negative Binomial specification handles variance better than Poisson and is the recommended model for inference and prediction.\n\n## 4.4: Model fit(AIC) Comparison\n\n**Question 6.2:** Which model fits better (lower AIC)? What does this tell you about the data?\n\n*Your answer here:*\n\n# Part 6: Spatial Cross-Validation\n\n（改）This section evaluates out-of-sample performance with Leave-One-Group-Out cross-validation where each police district is held out in turn. For every fold, the Negative Binomial model is trained on all other districts and then used to predict burglary counts in the held-out district. We then summarize prediction errors to assess how well the model generalizes across space.\n\n## 6.1: Create a Kernel Density Baseline\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated KDE baseline\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"KDE Value\",\n    option = \"plasma\"\n  ) +\n  labs(\n    title = \"Kernel Density Estimation Baseline\",\n    subtitle = \"Simple spatial smoothing of burglary locations\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-kde-1.png){width=768}\n:::\n:::\n\n\nBefore building complex models, let's create a simple baseline using **Kernel Density Estimation (KDE)**.\n\n**The KDE baseline asks:** \"What if crime just happens where it happened before?\" (simple spatial smoothing, no predictors)\n\n**Question 3.1:** How does the KDE map compare to the count map? What does KDE capture well? What does it miss?\n\n*Your answer here:* - Comparison to the count map: - KDE pros and cons:\n\n::: callout-tip\n## Why Start with KDE?\n\nThe KDE represents our **null hypothesis**: burglaries happen where they happened before, with no other information.\n\n**Your complex model must outperform this simple baseline to justify its complexity.**\n\nWe'll compare back to this at the end!\n:::\n\n## 6.2: **Leave-One-Group-Out (LOGO) Cross-Validation**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning LOGO Cross-Validation...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ lights_out + lights_out.nn + \n      dist_to_hotspot + med_income + pct_65_over + count_vacant,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Fold 1 / 22 - District 5 - MAE: 2.13 \n  Fold 2 / 22 - District 4 - MAE: 2.36 \n  Fold 3 / 22 - District 22 - MAE: 2.25 \n  Fold 4 / 22 - District 6 - MAE: 3.2 \n  Fold 5 / 22 - District 8 - MAE: 3.33 \n  Fold 6 / 22 - District 7 - MAE: 2.91 \n  Fold 7 / 22 - District 3 - MAE: 6.21 \n  Fold 8 / 22 - District 2 - MAE: 2.84 \n  Fold 9 / 22 - District 9 - MAE: 3.29 \n  Fold 10 / 22 - District 10 - MAE: 2.63 \n  Fold 11 / 22 - District 1 - MAE: 2.34 \n  Fold 12 / 22 - District 12 - MAE: 3.56 \n  Fold 13 / 22 - District 15 - MAE: 1.98 \n  Fold 14 / 22 - District 11 - MAE: 3.14 \n  Fold 15 / 22 - District 18 - MAE: 2.21 \n  Fold 16 / 22 - District 25 - MAE: 2.87 \n  Fold 17 / 22 - District 14 - MAE: 3.14 \n  Fold 18 / 22 - District 19 - MAE: 2.07 \n  Fold 19 / 22 - District 16 - MAE: 2.25 \n  Fold 20 / 22 - District 17 - MAE: 1.69 \n  Fold 21 / 22 - District 20 - MAE: 1.85 \n  Fold 22 / 22 - District 24 - MAE: 2.01 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Cross-Validation Complete\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean MAE: 2.74 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean RMSE: 3.67 \n```\n\n\n:::\n:::\n\n\n## 6.3: **Error metrics calculation and report**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>LOGO CV Results by District</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> fold </th>\n   <th style=\"text-align:left;\"> test_district </th>\n   <th style=\"text-align:right;\"> n_test </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 120 </td>\n   <td style=\"text-align:right;\"> 6.21 </td>\n   <td style=\"text-align:right;\"> 7.87 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:left;\"> 12 </td>\n   <td style=\"text-align:right;\"> 203 </td>\n   <td style=\"text-align:right;\"> 3.56 </td>\n   <td style=\"text-align:right;\"> 4.91 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> 8 </td>\n   <td style=\"text-align:right;\"> 419 </td>\n   <td style=\"text-align:right;\"> 3.33 </td>\n   <td style=\"text-align:right;\"> 4.17 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:right;\"> 291 </td>\n   <td style=\"text-align:right;\"> 3.29 </td>\n   <td style=\"text-align:right;\"> 4.83 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:left;\"> 6 </td>\n   <td style=\"text-align:right;\"> 154 </td>\n   <td style=\"text-align:right;\"> 3.20 </td>\n   <td style=\"text-align:right;\"> 4.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:left;\"> 11 </td>\n   <td style=\"text-align:right;\"> 124 </td>\n   <td style=\"text-align:right;\"> 3.14 </td>\n   <td style=\"text-align:right;\"> 3.79 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 17 </td>\n   <td style=\"text-align:left;\"> 14 </td>\n   <td style=\"text-align:right;\"> 164 </td>\n   <td style=\"text-align:right;\"> 3.14 </td>\n   <td style=\"text-align:right;\"> 4.66 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:left;\"> 7 </td>\n   <td style=\"text-align:right;\"> 149 </td>\n   <td style=\"text-align:right;\"> 2.91 </td>\n   <td style=\"text-align:right;\"> 3.77 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:right;\"> 228 </td>\n   <td style=\"text-align:right;\"> 2.87 </td>\n   <td style=\"text-align:right;\"> 3.82 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 8 </td>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 183 </td>\n   <td style=\"text-align:right;\"> 2.84 </td>\n   <td style=\"text-align:right;\"> 3.48 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:left;\"> 10 </td>\n   <td style=\"text-align:right;\"> 173 </td>\n   <td style=\"text-align:right;\"> 2.63 </td>\n   <td style=\"text-align:right;\"> 3.37 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 418 </td>\n   <td style=\"text-align:right;\"> 2.36 </td>\n   <td style=\"text-align:right;\"> 4.21 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 60 </td>\n   <td style=\"text-align:right;\"> 2.34 </td>\n   <td style=\"text-align:right;\"> 3.23 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:left;\"> 22 </td>\n   <td style=\"text-align:right;\"> 229 </td>\n   <td style=\"text-align:right;\"> 2.25 </td>\n   <td style=\"text-align:right;\"> 2.69 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:left;\"> 16 </td>\n   <td style=\"text-align:right;\"> 296 </td>\n   <td style=\"text-align:right;\"> 2.25 </td>\n   <td style=\"text-align:right;\"> 2.63 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:left;\"> 18 </td>\n   <td style=\"text-align:right;\"> 95 </td>\n   <td style=\"text-align:right;\"> 2.21 </td>\n   <td style=\"text-align:right;\"> 3.65 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:right;\"> 191 </td>\n   <td style=\"text-align:right;\"> 2.13 </td>\n   <td style=\"text-align:right;\"> 2.93 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:left;\"> 19 </td>\n   <td style=\"text-align:right;\"> 234 </td>\n   <td style=\"text-align:right;\"> 2.07 </td>\n   <td style=\"text-align:right;\"> 2.57 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 22 </td>\n   <td style=\"text-align:left;\"> 24 </td>\n   <td style=\"text-align:right;\"> 111 </td>\n   <td style=\"text-align:right;\"> 2.01 </td>\n   <td style=\"text-align:right;\"> 2.71 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:left;\"> 15 </td>\n   <td style=\"text-align:right;\"> 77 </td>\n   <td style=\"text-align:right;\"> 1.98 </td>\n   <td style=\"text-align:right;\"> 2.60 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:left;\"> 20 </td>\n   <td style=\"text-align:right;\"> 79 </td>\n   <td style=\"text-align:right;\"> 1.85 </td>\n   <td style=\"text-align:right;\"> 2.19 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:left;\"> 17 </td>\n   <td style=\"text-align:right;\"> 206 </td>\n   <td style=\"text-align:right;\"> 1.69 </td>\n   <td style=\"text-align:right;\"> 2.05 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Question 7.1:** Why is spatial CV more appropriate than random CV for this problem? Which districts were hardest to predict?\n\n*Your answer here:*\n\n# Part 7: Model **Evaluation**\n\n## 7.1: Generate Final Predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ lights_out + lights_out.nn + \n    dist_to_hotspot + med_income + pct_65_over + count_vacant,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n:::\n\n\n## 7.2: Compare Model vs. KDE Baseline\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/compare-models-1.png){width=1440}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Model Performance Comparison</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> approach </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> model </td>\n   <td style=\"text-align:right;\"> 2.60 </td>\n   <td style=\"text-align:right;\"> 3.63 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> kde </td>\n   <td style=\"text-align:right;\"> 2.17 </td>\n   <td style=\"text-align:right;\"> 3.06 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Question 8.1:** Does the complex model outperform the simple KDE baseline? By how much? Is the added complexity worth it?\n\n*Your answer here:*\n\n## 7.3: Where Does the Model Work Well?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate errors\nfishnet <- fishnet %>%\n  mutate(\n    error_nb = countBurglaries - prediction_nb,\n    error_kde = countBurglaries - prediction_kde,\n    abs_error_nb = abs(error_nb),\n    abs_error_kde = abs(error_kde)\n  )\n\n# Map errors\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(\n    name = \"Error\",\n    low = \"#2166ac\", mid = \"white\", high = \"#b2182b\",\n    midpoint = 0,\n    limits = c(-10, 10)\n  ) +\n  labs(title = \"Model Errors (Actual - Predicted)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Abs. Error\", option = \"plasma\") +\n  labs(title = \"Absolute Model Errors\") +\n  theme_crime()\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/prediction-errors-1.png){width=960}\n:::\n:::\n\n\n**Question 9.2:** Where does the model make the biggest errors? Are there spatial patterns in the errors? What might this reveal?\n\n*Your answer here:*\n\n# Part 8: Summary Statistics and Tables\n\n## 8.1: Model Summary Table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create nice summary table\nmodel_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%\n  mutate(\n    across(where(is.numeric), ~round(., 3))\n  )\n\nmodel_summary %>%\n  kable(\n    caption = \"Final Negative Binomial Model Coefficients (Exponentiated)\",\n    col.names = c(\"Variable\", \"Rate Ratio\", \"Std. Error\", \"Z\", \"P-Value\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  footnote(\n    general = \"Rate ratios > 1 indicate positive association with burglary counts.\"\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;border-bottom: 0;\">\n<caption>Final Negative Binomial Model Coefficients (Exponentiated)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> Rate Ratio </th>\n   <th style=\"text-align:right;\"> Std. Error </th>\n   <th style=\"text-align:right;\"> Z </th>\n   <th style=\"text-align:right;\"> P-Value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 9.770 </td>\n   <td style=\"text-align:right;\"> 0.058 </td>\n   <td style=\"text-align:right;\"> 38.975 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lights_out </td>\n   <td style=\"text-align:right;\"> 1.004 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n   <td style=\"text-align:right;\"> 3.628 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lights_out.nn </td>\n   <td style=\"text-align:right;\"> 0.997 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -22.438 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dist_to_hotspot </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -5.202 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> med_income </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -5.268 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> pct_65_over </td>\n   <td style=\"text-align:right;\"> 0.978 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n   <td style=\"text-align:right;\"> -8.995 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> count_vacant </td>\n   <td style=\"text-align:right;\"> 1.002 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 4.255 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Rate ratios &gt; 1 indicate positive association with burglary counts.</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n## 8.2: Key Findings Summary\n\nBased on your analysis, complete this summary:\n\n**Technical Performance:**\n\n-   Cross-validation MAE: 2.74\n-   Model vs. KDE: \\[Which performed better?\\]\n-   Most predictive variable: \\[Which had largest effect?\\]\n\n**Spatial Patterns:**\n\n-   Burglaries are \\[evenly distributed / clustered\\]\n-   Hot spots are located in \\[describe\\]\n-   Model errors show \\[random / systematic\\] patterns\n\n**Model Limitations:**\n\n-   Overdispersion: \\[Yes/No\\]\n-   Spatial autocorrelation in residuals: \\[Test this!\\]\n-   Cells with zero counts: \\[What % of data?\\]\n",
    "supporting": [
      "assignment4_template_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}